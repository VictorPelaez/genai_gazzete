{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run example in notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HlYdYNtUHOB"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade newsapi-python transformers python-docx diffusers scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcLqIGHVVmgw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "import time\n",
        "from utils import readConfig, clear_article\n",
        "\n",
        "from newsapi import NewsApiClient\n",
        "# --------------------------\n",
        "\n",
        "fdate = '2023-08-03'\n",
        "\n",
        "## NEWS_API\n",
        "config = readConfig()\n",
        "session_config = config['local_session']\n",
        "api_key = session_config['api_key']\n",
        "newsapi = NewsApiClient(api_key=api_key)\n",
        "all_articles = newsapi.get_everything(q='generative ai llms',\n",
        "                                      language='en',\n",
        "                                      from_param=fdate,\n",
        "                                      sort_by='relevancy')\n",
        "\n",
        "print(\"#articles: \", len(all_articles[\"articles\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTYVUVDHedgf"
      },
      "source": [
        "## SUMMARIZATION MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEtaBo8_WJ7j"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "from transformers import pipeline\n",
        "\n",
        "# --------------------------\n",
        "\n",
        "model_name = \"sshleifer/distilbart-cnn-12-6\" #\"sshleifer/bart-large-cnn\" #\"sshleifer/distilbart-xsum-12-1\" \"google/flan-t5-base\"\n",
        "summarizer = pipeline('summarization', model=\"sshleifer/distilbart-cnn-12-6\")#, device=0) # T4 GPU in Colab\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "## Data to feed\n",
        "N = int(round(len(all_articles[\"articles\"])*0.1, 0)) #number to show, verbose\n",
        "L = 3000 #context size\n",
        "df = pd.DataFrame(columns = [\"source\", \"url\", \"title\", \"description\", \"len_text\", \"summary\"])\n",
        "\n",
        "for i, a in enumerate(all_articles[\"articles\"]):\n",
        "\n",
        "  start = time.time()\n",
        "  print(dash_line)\n",
        "  print('Example ', i + 1)\n",
        "  print(dash_line)\n",
        "\n",
        "  # read url HTLM web\n",
        "  page = requests.get(a[\"url\"])\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  result = soup.find_all([\"p\",\"i\"]) # Slashdot is <i>\n",
        "  ARTICLE = \"\"\n",
        "  for part in result:\n",
        "    if (part.get(\"class\")==None) and len(ARTICLE)<L:\n",
        "      ARTICLE = ARTICLE + \" \" + part.get_text()\n",
        "\n",
        "  ARTICLE = clear_article(ARTICLE)\n",
        "\n",
        "  if len(ARTICLE)>0:\n",
        "    summarized_article = summarizer(ARTICLE)[0][\"summary_text\"]\n",
        "    summarized_article = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', summarized_article) #remove whitespaces\n",
        "  else:\n",
        "    summarized_article = \"empty\"\n",
        "\n",
        "  df = df.append({'source': a['source']['name'],\n",
        "                  'url': a[\"url\"],\n",
        "                  'title': a[\"title\"],\n",
        "                  'description': a[\"description\"],\n",
        "                  'len_text': len(ARTICLE),\n",
        "                  'summary': summarized_article}, ignore_index = True)\n",
        "\n",
        "  # print samples\n",
        "  if (i<N) and (len(ARTICLE)>0) :\n",
        "    print(a['source']['name'], a[\"url\"])\n",
        "    print('Description:  ', a['description'])\n",
        "    print('LLM Summary')\n",
        "    print(df.iloc[i][\"summary\"])\n",
        "\n",
        "  end = time.time()\n",
        "  print(end - start)\n",
        "  print(dash_line)\n",
        "  print()\n",
        "\n",
        "df.drop_duplicates(subset=['source', 'title'], keep='first', inplace=True)\n",
        "df.drop(df[df[\"summary\"]==\"empty\"].index, inplace=True)\n",
        "df = df[df['summary'].apply(lambda s: (\"llms\" in s) | (\"llm\" in s) | (\"generative ai\" in s) | (\"ai\" in s))]\n",
        "print(df.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFAY2k97ohrT"
      },
      "source": [
        "# Image generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5WDEMmFo0O6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "device = \"cuda\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(device)\n",
        "\n",
        "#prompt = \"Google Assistant Is Getting a Major Upgrade, pastel colors, Victorian style\"\n",
        "#image = pipe(prompt).images[0]\n",
        "#image.save(\"image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICoqPBw5jNTs"
      },
      "source": [
        "## Document Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf2a_k-t-xKi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws6F3mGbo2OJ"
      },
      "outputs": [],
      "source": [
        "from functions_doc import get_or_create_hyperlink_style, add_hyperlink\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "from datetime import date\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# document creation\n",
        "# -----------------------------------------------------\n",
        "\n",
        "today = date.today()\n",
        "document = Document()\n",
        "# document.add_heading(\"Check out the most popular articles about Generative AI and LLMs in a nutshell!\", 0)\n",
        "document.add_picture('/content/drive/MyDrive/LLMs coursera/20230804_130845_0000.png', width=Inches(6), height=Inches(1.2))\n",
        "last_paragraph = document.paragraphs[-1]\n",
        "last_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "p = document.add_paragraph()\n",
        "runner = p.add_run(fdate + \" - \" + str(today)).italic = True\n",
        "last_paragraph = document.paragraphs[-1]\n",
        "last_paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
        "\n",
        "for r in df.index:\n",
        "  # 1. add title\n",
        "  document.add_heading('[' + df[\"source\"][r] + '] ' +df[\"title\"][r], level=1)\n",
        "  # 2. add link\n",
        "  p = document.add_paragraph()\n",
        "  add_hyperlink(p, 'Original article', df[\"url\"][r])\n",
        "\n",
        "  # 3. create image and add it\n",
        "  prompt_style= \" sci-fi style, pen and ink, pastel colors\"\n",
        "  image = pipe(df[\"title\"][r] + prompt_style).images[0]\n",
        "  image.save(\"image.png\")\n",
        "  document.add_picture('image.png', width=Inches(2), height=Inches(2))\n",
        "  last_paragraph = document.paragraphs[-1]\n",
        "  last_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "  # 4. add summary\n",
        "  document.add_paragraph(df[\"summary\"][r], style='Intense Quote')\n",
        "  p = document.add_paragraph()\n",
        "  p.paragraph_format.line_spacing = Inches(0.3)\n",
        "\n",
        "document.save('/content/drive/MyDrive/LLMs coursera/summarized_articles.docx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
